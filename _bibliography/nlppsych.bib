---
layout: default
title: CV
---

@misc{kennedy2020moral,
 title={Moral Concerns are Differentially Observable in Language},
 abstract={Language is a psychologically rich medium for human expression and communication. While it is often used in moral psychology as an intermediary between researcher and participant, much of the human experience that occurs through language — our relationships, conversations, and, in general, the everyday transmission of our thoughts — has yet to be studied in association with moral concerns. In order to understand how moral concerns relate to observed language usage, we paired Facebook status updates (N = 107,798) from English-speaking participants (n = 2,691) with their responses on the Moral Foundations Questionnaire, which measures Care, Fairness, Loyalty, Authority, and Purity concerns. Overall, we found consistent evidence that participants’ self-reported moral concerns can be predicted from their language, though the magnitude of this effect varied considerably among concerns. Across a diverse selection of Natural Language Processing methods, cross-validated R2 values ranged from 0.04 for predicting Fairness concerns to 0.21for predicting Purity concerns. In follow-up analyses, each moral concern was found to be related to distinct patterns of relational, emotional, and social language. Our results are the first finding relating internally valid measures of moral concerns to observations of language, motivating several new avenues for exploring and investigating how the moral domain intersects with language usage.},
 url={psyarxiv.com/uqmty},
 DOI={10.31234/osf.io/uqmty},
 publisher={PsyArXiv},
 author={Kennedy, Brendan and Atari, Mohammad and Mostafazadeh Davani, Aida and Hoover, Joseph and Omrani, Ali and Graham, Jesse and Dehghani, Morteza},
 year={2020},
 month={May}
}
,
@article{garten2019demographic,
    title = {Incorporating Demographic Embeddings Into Language Understanding},
    abstract = {Meaning depends on context. This applies in obvious cases like deictics or sarcasm as well as more subtle situations like framing or persuasion. One key aspect of this is the identity of the participants in an interaction. Our interpretation of an utterance shifts based on a variety of factors, including personal history, background knowledge, and our relationship to the source. While obviously an incomplete model of individual differences, demographic factors provide a useful starting point and allow us to capture some of this variance. However, the relevance of specific demographic factors varies between situations—where age might be the key factor in one context, ideology might dominate in another. To address this challenge, we introduce a method for combining demographics and context into situated demographic embeddings—mapping representations into a continuous geometric space appropriate for the given domain, showing the resulting representations to be functional and interpretable. We further demonstrate how to make use of related external data so as to apply this approach in low‐resource situations. Finally, we show how these representations can be incorporated into improve modeling of real‐world natural language understanding tasks, improving model performance and helping with issues of data sparsity.},
    journal = {Cognitive Science},
    year = {2019},
    volume = {43},
    number = {1},
    author = {Garten, J. and Kennedy, B. and Hoover, J. and Sagae, K. and Dehghani, M.}, 
    doi={10.1111/cogs.12701}
}
,
@article{hoover2020mftc,
    title = {Moral Foundations Twitter Corpus: A Collection of 35k Tweets Annotated for Moral Sentiment},
    abstract = {Research has shown that accounting for moral sentiment in natural language can yield insight into a variety of on- and off-line phenomena such as message diffusion, protest dynamics, and social distancing. However, measuring moral sentiment in natural language is challenging, and the difficulty of this task is exacerbated by the limited availability of annotated data. To address this issue, we introduce the Moral Foundations Twitter Corpus, a collection of 35,108 tweets that have been curated from seven distinct domains of discourse and hand annotated by at least three trained annotators for 10 categories of moral sentiment. To facilitate investigations of annotator response dynamics, we also provide psychological and demographic metadata for each annotator. Finally, we report moral sentiment classification baselines for this corpus using a range of popular methodologies.},
    journal = {Social Psychological and Personality Science},
    year = {2020},
    author = {Hoover, J. and Portillo-Wightman, G. and Yeh, L. and Havaldar, S. and Davani, A.M. and Lin, Y. and Kennedy, B. and Atari, M. and Kamel, Z. and Mendlen, M. and Moreno, G. and Park, C. and Chang, T.E. and Chin, J. and Leong, C. and Leung, J.Y. and Mirinjian, A. and Dehghani, M.}}
,
@inproceedings{mostafazadeh2020hatred,
  author = {Mostafazadeh Davani, Aida and Atari, Mohammad and Kennedy, Brendan and Havaldar, Shreya and Dehghani, Morteza},
  title = {Hatred is in the Eye of the Annotator: Hate Speech Classifiers Learn Human-Like Social Stereotypes (in press)},
  abstract = {Social stereotypes impact individuals' judgement about different social groups. One area where such stereotyping has a critical impact is in hate speech detection, in which human annotations of text are used to train machine learning models. Such models are likely to be biased in the same ways that humans are biased in their judgments of social groups. In this research, we investigate the effect of stereotypes of social groups on the performance of expert annotators in a large corpus of annotated hate speech. We also examine the effect of these stereotypes on unintended bias of hate speech classifiers. To this end, we show how language-encoded stereotypes, associated with social groups, lead to disagreements in identifying hate speech. Lastly, we analyze how inconsistencies in annotations propagate to a supervised classifier when human-generated labels are used to train a hate speech detection model.},
  booktitle = {31st Annual Conference of the Cognitive Science Society (CogSci)},
  year = {2020}
}

